# Reddit Analytics Platform - Supabase Integration Design

## 1. Project Overview

This document outlines the integration of our existing Reddit data processing project with Supabase, focusing on optimizing data fetching and storage mechanisms.

### Current Challenges

- Reddit data and OpenAI API are called every time a user opens a subreddit page
- This approach is inefficient and creates unnecessary API calls
- No data persistence between sessions
- Repeated processing of the same data

### Integration Goals

- Connect the application to Supabase for data persistence
- Store Reddit posts and AI analysis results
- Implement a caching mechanism with a 24-hour refresh policy
- Optimize API usage by only fetching new data when necessary

## 2. Current Project Structure

### Key Folders and Files

```
reddit-analytics-platform/
└── web/
    ├── public/
    ├── src/
    │   ├── app/
    │   │   ├── layout.tsx
    │   │   ├── page.tsx                    // Homepage with subreddit cards
    │   │   ├── api/
    │   │   │   └── reddit/
    │   │   │       ├── [subreddit]/
    │   │   │       │   ├── posts/
    │   │   │       │   │   └── route.ts    // API endpoint for fetching posts
    │   │   │       │   └── themes/
    │   │   │       │       └── route.ts    // API endpoint for theme analysis
    │   │   └── [subreddit]/
    │   │       └── page.tsx                // Subreddit details page
    │   ├── components/
    │   │   └── ui/
    │   │       ├── card.tsx                // shadcn/ui components
    │   │       └── ...
    │   └── lib/
    │       ├── reddit/
    │       │   ├── Instructions/
    │       │   │   └── instructions.md     // Project requirements & documentation
    │       │   ├── snoowrap.ts            // Reddit API client & fetch logic
    │       │   └── analyzeRedditPosts.ts   // Reddit post analysis logic
    │       ├── analysis.ts                 // OpenAI integration for theme analysis
    │       └── analyzeRedditPosts.ts       // Post categorization logic
    ├── package.json
    └── node_modules/
    ```

Currently, the app fetches Reddit data each time a user opens a particular subreddit page (`/[subreddit]/page.tsx`) and calls the OpenAI API for classification. This can be inefficient.

## 3. Proposed Supabase Integration

The **Supabase integration** will act as a data layer between the application and the Reddit/OpenAI services. The flow will be:

1. **Check if data is stale** (older than 24 hours) in Supabase.  
2. If stale or not present:
   - Fetch fresh data from Reddit.
   - Run thematic analysis (OpenAI).
   - Update or insert the new data in Supabase.
3. If data is fresh (less than 24 hours old):
   - Use the existing cached data in Supabase.

### 3.1 Where to Integrate the Logic

- **`src/lib/reddit/`**: Extend (or wrap) the existing `fetchRecentPosts` logic to first query Supabase for any cached posts. If the data is older than 24 hours (or doesn't exist), call Snoowrap to fetch new data, then store results in Supabase.  
- **`src/lib/analysis.ts`**: Similar approach for running AI classification. Check if posts have been analyzed. If not, call OpenAI, then store the classification in Supabase.  

The actual triggers/conditions (e.g., "if older than 24 hours") can live in the same library function or in a separate utility for clarity.

## 4. Database Schema and Tables

Below is a recommended minimal schema for storing Reddit posts and their associated thematic analyses. You can modify or extend it as your project grows.

### 4.1 `subreddits` Table

| Column          | Type            | Description                                                   |
|-----------------|-----------------|---------------------------------------------------------------|
| `id` (PK)       | UUID            | Primary key, generated by Supabase (or `SERIAL`/`BIGSERIAL`). |
| `name`          | text            | Name of the subreddit (e.g., "ollama").                      |
| `created_at`    | timestamp/UTC   | Supabase default.                                            |
| `updated_at`    | timestamp/UTC   | Manually updated whenever new data is fetched.               |

#### Usage
- Store unique subreddits that users have added via the "Add Subreddit" modal.  
- `updated_at` helps track the last time fresh data was fetched for that subreddit.

### 4.2 `reddit_posts` Table

| Column          | Type            | Description                                                           |
|-----------------|-----------------|-----------------------------------------------------------------------|
| `id` (PK)       | text            | Reddit's post ID (unique enough in the context of a subreddit).      |
| `subreddit_id`  | UUID (FK)       | Foreign key referencing `subreddits.id`.                             |
| `title`         | text            | The post's title.                                                    |
| `content`       | text            | The post's selftext (if any).                                        |
| `score`         | integer         | The post's Reddit score.                                             |
| `num_comments`  | integer         | Number of comments in the post.                                      |
| `url`           | text            | URL to the post.                                                     |
| `created_at`    | timestamp/UTC   | The post's creation time (converted to a UTC time from Reddit).      |
| `permalink`     | text            | The post's relative Reddit permalink.                                |
| `fetched_at`    | timestamp/UTC   | Timestamp when this post was inserted or last updated in Supabase.   |

#### Usage
- Each row represents a single Reddit post.  
- `fetched_at` indicates when the data was last fetched from Reddit. You'll compare this to the current time to see if it's older than 24 hours.

### 4.3 `post_analysis` (or `post_themes`) Table

| Column          | Type            | Description                                                       |
|-----------------|-----------------|-------------------------------------------------------------------|
| `analysis_id`   | UUID (PK)       | Primary key.                                                      |
| `post_id`       | text (FK)       | Foreign key referencing `reddit_posts.id`.                        |
| `theme`         | text            | The theme category assigned (e.g., "solution requests").          |
| `analysis_date` | timestamp/UTC   | Timestamp indicating when the analysis was performed.             |

#### Usage
- Holds the result of calling OpenAI.  
- You can store a single assigned theme per post. Alternatively, if multi-label classification is needed, you can have multiple rows for each post.  
- `analysis_date` helps track when the analysis was done. If a new theme is added, you can re-run analysis and either insert a new row or update existing ones.

### 4.4 (Optional) `themes` Table

If you prefer to manage a dynamic list of all possible themes (including newly added ones), a separate `themes` table can store the canonical list of theme names. Then, `post_analysis.theme` could be a foreign key to this table. This is optional; you can also store theme strings directly in `post_analysis`.

## 5. Data Fetching & Caching Logic

1. **User Requests Subreddit Page**  
   - The system checks **Supabase** for the given subreddit's `updated_at`.  
   - If `updated_at` + 24 hours <= now, it means data is stale.  
   - If stale, call `fetchRecentPosts` from Snoowrap and store the data in Supabase.  
     - Insert or update each **`reddit_posts`** record.  
     - Run the analysis logic from **`src/lib/analysis.ts`** on each post, then store in **`post_analysis`**.  
     - Update the subreddit's `updated_at` in the **`subreddits`** table.  
   - If not stale, fetch existing data from Supabase directly.  

2. **Themes Tab**  
   - For each post, retrieve the theme classification from **`post_analysis`**.  
   - Group or filter posts by these themes to deliver the final UI.

3. **Adding a New Theme**  
   - When a user adds a theme, you can store it in a **`themes`** table (optional) or handle it dynamically in code.  
   - Consider re-running analysis for all posts if you want to classify them under the new theme (depending on whether your classification approach is single-label or multi-label).  
   - If you do re-run analysis, update **`post_analysis`** accordingly.

## 6. Implementation Outline

### 6.1 Database Client Setup
- Use the official Supabase SDK or a Postgres client (e.g., `pg`) if you prefer direct SQL.  
- Store the **Supabase Project URL** and **API Key** in environment variables.

### 6.2 Supabase Insert/Update Methods
- Create utility functions in **`src/lib/db/`** (new folder) to:
  - **Insert or update** a row in the `reddit_posts` table.  
  - **Insert or update** analysis results in the `post_analysis` table.  

### 6.3 Tying It All Together
- **`fetchRecentPostsExtended(...)`**: A new function that checks Supabase first, decides whether to fetch from Reddit, and returns final data.  
- **`analyzePost(...)`**: A function that checks if a given post already has theme data. If not, or if a re-analysis is needed, calls OpenAI and updates Supabase.

## 7. Usage Flow in the Frontend

1. **User opens** `/[subreddit]/page.tsx`.  
2. A server-side or client-side call triggers your new **extended fetch function**.  
3. The function returns an **up-to-date** list of posts from Supabase, ensuring no fresh data is needed from Reddit if the last fetch was under 24 hours ago.  
4. The UI displays the posts and their themes.

## 8. Considerations

1. **Error Handling**:  
   - If the Reddit API call fails, log and retry or fall back to existing cached data if it's available.  

2. **Security**:  
   - Use a **service key** in a secure environment or rely on Supabase Row Level Security (RLS) if you want stricter data access policies.  

3. **Performance**:  
   - If the user loads very large subreddits, consider pagination. Supabase's SQL queries should handle offset/limit or keyset pagination.  

4. **Scalability**:  
   - For heavier usage, you might consider background cron jobs to periodically refresh data for each subreddit, so users don't incur the data fetching overhead on page load.  

5. **Multiple Themes per Post**:  
   - If you choose to support multiple themes for a single post, the data model will need to allow multiple rows in `post_analysis` referencing the same `post_id` with different `theme` values.  

6. **OpenAI Token Usage**:  
   - Keep track of how often you're calling the AI for classification. Storing the results in Supabase drastically reduces repeated calls for the same posts.  

## 9. Summary

By introducing Supabase into the Reddit Analytics Platform:

- We reduce repeated API calls (Reddit & OpenAI).  
- We cache data effectively in a Postgres database.  
- We keep the existing Next.js front-end logic mostly intact by adding an intermediate **check/update** step.  

This design document should guide your backend engineer to implement Supabase integration in a way that cleanly fits into the current project architecture, addressing the key requirement of **only re-fetching data if older than 24 hours** while retaining the project's minimalistic approach.